{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84947707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zacharydemanche/anaconda3/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/Users/zacharydemanche/anaconda3/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's response: At UConn, we offer over 100 undergraduate majors across a wide range of disciplines. From business and engineering to liberal arts and sciences, there is something for everyone at UConn. Our diverse academic offerings provide students with the opportunity to explore their interests and pursue their passions in a supportive and innovative environment. Whether you're interested in pursuing a career in healthcare, technology, or the arts, UConn has a program that will help you achieve your goals and prepare you for success in your chosen field.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "model_path = \"saved_model_t5_normal_complete\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "def generate_response(prompt):\n",
    "    input_text = \"question: \" + prompt \n",
    "    print(\" \")\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    \n",
    "    # Updated parameters for model.generate()\n",
    "    output = model.generate(\n",
    "        input_ids, \n",
    "        max_length=150, \n",
    "        num_return_sequences=1,\n",
    "        num_beams=5,       # Using beam search with 5 beams\n",
    "        temperature=0.7,   # Moderately random outputs\n",
    "        top_k=50,          # Only consider top 50 tokens for each step\n",
    "        top_p=0.95         # Use nucleus sampling with p=0.95\n",
    "    )\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test the model with user prompts\n",
    "while True:\n",
    "    print(\" \")\n",
    "    user_input = input(\"Enter your prompt (or 'quit' to exit): \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    \n",
    "    generated_response = generate_response(user_input)\n",
    "    print(\"Model's response:\", generated_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
